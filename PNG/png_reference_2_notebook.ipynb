{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "from pydantic import BaseModel\n",
    "import base64\n",
    "import json\n",
    "import base64\n",
    "from http import client\n",
    "import json\n",
    "from pathlib import Path\n",
    "from mistralai import Mistral, TextChunk\n",
    "from mistralai import ImageURLChunk\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Mistral client with your API key\n",
    "api_key = \"____\"\n",
    "client = Mistral(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StructuredOCR:\n",
    "    file_name: str  # can be any string\n",
    "    topics: list[str]  # must be a list of strings\n",
    "    languages: str  # string\n",
    "    ocr_contents: dict  # any dictionary, can be freely defined by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StructuredOCR(BaseModel):\n",
    "    file_name: str\n",
    "    topics: list[str]\n",
    "    languages: str\n",
    "    ocr_contents: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structured_ocr(image_path: str) -> StructuredOCR:\n",
    "    \"\"\"\n",
    "    Process an image using OCR and extract structured data.\n",
    "\n",
    "    Args:\n",
    "        image_path: Path to the image file to process\n",
    "\n",
    "    Returns:\n",
    "        StructuredOCR object containing the extracted data\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: If the image file does not exist\n",
    "    \"\"\"\n",
    "    # Validate input file\n",
    "    image_file = Path(image_path)\n",
    "    assert image_file.is_file(), \"The provided image path does not exist.\"\n",
    "\n",
    "    # Read and encode the image file\n",
    "    encoded_image = base64.b64encode(image_file.read_bytes()).decode()\n",
    "    base64_data_url = f\"data:image/jpeg;base64,{encoded_image}\"\n",
    "\n",
    "    # Process the image using OCR\n",
    "    image_response = client.ocr.process(\n",
    "        document=ImageURLChunk(image_url=base64_data_url),\n",
    "        model=\"mistral-ocr-latest\"\n",
    "    )\n",
    "    image_ocr_markdown = image_response.pages[0].markdown\n",
    "\n",
    "    # Parse the OCR result into a structured JSON response\n",
    "    chat_response = client.chat.parse(\n",
    "        model=\"pixtral-12b-latest\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    ImageURLChunk(image_url=base64_data_url),\n",
    "                    TextChunk(text=(\n",
    "                        f\"This is the image's OCR in markdown:\\n{image_ocr_markdown}\\n.\\n\"\n",
    "                        \"Convert this into a structured JSON response \"\n",
    "                        \"with the OCR contents in a sensible dictionnary.\"\n",
    "                        )\n",
    "                    )\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        response_format=StructuredOCR,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return chat_response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "image_path = \"receipt.png\" # Path to sample receipt image\n",
    "structured_response = structured_ocr(Path(image_path)) # Process image and extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse and return JSON response\n",
    "response_dict = json.loads(structured_response.model_dump_json())\n",
    "print(json.dumps(response_dict, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize the image\n",
    "image = Image.open(image_path)\n",
    "image.resize((image.width // 5, image.height // 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
